{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd077308f10e778eec9a13a21206849a589a8c13410aaae2405e5051cd249c67e86",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# SFRD from IR based data\n",
    "\n",
    "Until now, we have been using UV observations to determine the luminosity functions and SFRDs from it. Now, let's turn our attention to the IR data. We currently have three references for such observations. We, for now, focus on these data. We try to propagate the errors correctly. Below, we show this computation. We also save the computed SFRDs from IR data for further uses."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.constants as con\n",
    "import os\n",
    "import utils as utl\n",
    "import irlf as irlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining kappa and luminosity range\n",
    "\n",
    "kap_ir = 4.5*10**(-44)\n",
    "lums_ir1 = np.logspace(6, 15, 10000)*con.L_sun.value*1e7\n",
    "\n",
    "\n",
    "# Making a list of IR data\n",
    "p1 = os.getcwd() + '/data/New_IR/'\n",
    "p2 = os.getcwd() + '/Results/'\n",
    "\n",
    "list1 = os.listdir(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10000/10000 [01:58<00:00, 84.27it/s]\n",
      "100%|██████████| 10000/10000 [02:00<00:00, 83.24it/s]\n",
      "100%|██████████| 10000/10000 [02:02<00:00, 81.84it/s]\n",
      "100%|██████████| 10000/10000 [02:00<00:00, 82.66it/s]\n",
      "100%|██████████| 10000/10000 [02:01<00:00, 82.09it/s]\n",
      "100%|██████████| 10000/10000 [02:01<00:00, 82.13it/s]\n",
      "100%|██████████| 10000/10000 [02:02<00:00, 81.61it/s]\n",
      "100%|██████████| 10000/10000 [02:02<00:00, 81.52it/s]\n",
      "100%|██████████| 10000/10000 [02:02<00:00, 81.90it/s]\n",
      "100%|██████████| 10000/10000 [02:02<00:00, 81.67it/s]\n",
      "100%|██████████| 10000/10000 [02:02<00:00, 81.72it/s]\n",
      "100%|██████████| 10000/10000 [02:01<00:00, 82.32it/s]\n",
      "100%|██████████| 10000/10000 [01:41<00:00, 98.59it/s]\n",
      "100%|██████████| 10000/10000 [01:39<00:00, 100.77it/s]\n",
      "100%|██████████| 10000/10000 [01:58<00:00, 84.51it/s]\n",
      "100%|██████████| 10000/10000 [01:25<00:00, 117.36it/s]\n",
      "100%|██████████| 10000/10000 [01:09<00:00, 144.76it/s]\n"
     ]
    }
   ],
   "source": [
    "f33 = open(p2 + 'sfrd_ir_new.dat','w')\n",
    "f33.write('#Name_of_the_paper\\tZ_down\\tZ_up\\tSFRD\\tSFRD_err\\n')\n",
    "\n",
    "for i in range(len(list1)):\n",
    "    z1_ir, z2_ir, alp_ir, alperr_ir, lst_ir, lsterr_ir, sig_ir, sigerr_ir, phi_ir, phierr_ir = np.loadtxt(p1 + list1[i], usecols=(0,1,2,3,4,5,6,7,8,9), unpack=True)\n",
    "    ppr_n1 = np.loadtxt(p1 + list1[i], usecols=10, dtype=str, unpack=True)\n",
    "    if type(alp_ir) == np.float64:\n",
    "        z1_ir, z2_ir, alp_ir, alperr_ir, lst_ir, lsterr_ir, sig_ir, sigerr_ir, phi_ir, phierr_ir, ppr_n1 = np.array([z1_ir]), np.array([z2_ir]), np.array([alp_ir]), np.array([alperr_ir]), np.array([lst_ir]), np.array([lsterr_ir]), np.array([sig_ir]), np.array([sigerr_ir]), np.array([phi_ir]), np.array([phierr_ir]), np.array([ppr_n1])\n",
    "    sfrd_ir12, sfrd_ir12_err = np.array([]), np.array([])\n",
    "    for j in range(len(z1_ir)):\n",
    "        sfrd_ir, sfrd_err_ir = irlf.sfrd_w_err(lum=lums_ir1, lst9=lst_ir[j], lst9err=lsterr_ir[j], phi9=phi_ir[j], phi9err=phierr_ir[j], sig9=sig_ir[j], sig9err=sigerr_ir[j], alp9=alp_ir[j], alp9err=alperr_ir[j], kappa=kap_ir, limit=0.03)\n",
    "        sfrd_ir12 = np.hstack((sfrd_ir12, sfrd_ir))\n",
    "        sfrd_ir12_err = np.hstack((sfrd_ir12_err, sfrd_err_ir))\n",
    "        f33.write(ppr_n1[0] + '\\t' + str(z1_ir[j]) + '\\t' + str(z2_ir[j]) + '\\t' + str(sfrd_ir) + '\\t' + str(sfrd_err_ir) + '\\n')\n",
    "\n",
    "f33.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:4: UserWarning: loadtxt: Empty input file: \"/home/jayshil/Documents/UNIGE/APL/APL2/csfrd/Results/sfrd_ir_new.dat\"\nipykernel_launcher:5: UserWarning: loadtxt: Empty input file: \"/home/jayshil/Documents/UNIGE/APL/APL2/csfrd/Results/sfrd_ir_new.dat\"\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 0)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2d7c97b188a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Loading papers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mppr_ir1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'sfrd_ir_new.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mzd_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzu_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfrd_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfrd_ir_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'sfrd_ir_new.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mzcen_ir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mzd_ir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mzu_ir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mzup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzu_ir\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mzcen_ir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzcen_ir\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mzd_ir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 0)"
     ]
    }
   ],
   "source": [
    "ppr_ir = np.array(['Takeuchi_et_al_2003', 'Gruppioni_et_al_2013', 'Gruppioni_et_al_2020'])\n",
    "\n",
    "# Loading papers\n",
    "ppr_ir1 = np.loadtxt(p2 + 'sfrd_ir_new.dat', usecols=0, unpack=True, dtype=str)\n",
    "zd_ir, zu_ir, sfrd_ir, sfrd_ir_err = np.loadtxt(p2 + 'sfrd_ir_new.dat', usecols=(1,2,3,4), unpack=True)\n",
    "zcen_ir = (zd_ir + zu_ir)/2\n",
    "zup, zdo = np.abs(zu_ir - zcen_ir), np.abs(zcen_ir - zd_ir)\n",
    "log_sfrd_ir, log_sfrd_ir_err = utl.log_err(sfrd_ir, sfrd_ir_err)\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "# Plotting them\n",
    "for i in range(len(ppr_ir)):\n",
    "    zc_ir, zp, zn, lg_sf, lg_sfe = np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
    "    for j in range(len(ppr_ir1)):\n",
    "        if ppr_ir1[j] == ppr_ir[i]:\n",
    "            zc_ir = np.hstack((zc_ir, zcen_ir[j]))\n",
    "            lg_sf = np.hstack((lg_sf, log_sfrd_ir[j]))\n",
    "            lg_sfe = np.hstack((lg_sfe, log_sfrd_ir_err[j]))\n",
    "            zp = np.hstack((zp, zup[j]))\n",
    "            zn = np.hstack((zn, zdo[j]))\n",
    "    plt.errorbar(zc_ir, lg_sf, yerr=lg_sfe, label=ppr_ir[i].replace('_',' ') + ' UV LF', fmt='o')\n",
    "\n",
    "#plt.plot(znew, psi2, label='Best fitted function')\n",
    "plt.xlabel('Redshift')\n",
    "plt.ylabel(r'$\\log{\\psi}$ ($M_\\odot year^{-1} Mpc^{-3}$)')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}